# 2024/12/29

**Done:**

- Ubuntu 系统安装，开发环境搭建。

  > 复制粘贴工具
  >
  > 磁盘管理工具
  >
  > anaconda 安装与彻底卸载
  >
  > Vscode Minianaconda
  >
  > 使用了nest_2_16_0 版本跑通代码，并且之后的各个依赖将参照该版本进行修改。

- Vscode 无法debug问题如何解决。

- Nest 平台 Ubuntu 环境安装配置，并部署基于 Nest 实现的 LSM 项目，实现对样例文件的运行。

- ``` python
  Traceback (most recent call last):
    File "/home/yundid/miniconda3/envs/RCnest_2_18_0/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 3236, in size
      return a.shape[axis]
  AttributeError: 'list' object has no attribute 'shape'
  # 报错原因 numpy 版本不对应，修改 RCnest_2_18_0 环境下的 numpy 版本与 RCnest_2_16_0 一致
  ```

- generate_stimulus_xor 是理解人物输入数据对象的关键

- XOR 的基准是什么？

  > 基准就是刺激时刻，两个神经元在对应的刺激时刻下是否有响应，有标记 state 为 1，否则为 0，基于所有的刺激时刻进行XOR运算。
  >
  > 但是这个值是一开始就假定的（随机），根据这个假定的状态和刺激时刻，进而生成神经元对应的 spike train。

- LSM 生成的特征，或者说是输入到输出层分类之前的特征。

  > 是合并后的高维特征向量
  >
  > 在指定的 `readout_times` 提取 **LSM 网络的状态**。
  >
  > 每次提取时，LSM 内部所有神经元的膜电位或者尖峰活动经过时间衰减（`tau=20`）处理后，生成一个高维状态向量。
  >
  > 换句话说，`states` 是在指定的 `readout_times` 时刻，**LSM 所有神经元的动态响应**的集合。

- 看一下 states 的维度是多少？

  > 661 * 501。
  >
  > 但代码中的 `n_rec=500` 表示只记录一部分神经元的状态作为输出（可能是从内部随机抽取了 500 个神经元）。
  >
  > 还额外增加了一个偏置，因此最终维度为 661 * 501 标识刺激后所有网络的动态响应。
  >
  > 但是发现分类器的权重 `readout_weights` 也是 501 
  >
  > 分类器的权重 `readout_weights` 对应了 `states` 的每个特征，最终将这 501 维特征映射到一个标量输出。
  >
  > 所以，`states` 和 `readout_weights` 的特征数必须保持一致，都是 `501`，这是因为分类器需要用到所有的状态特征来预测目标输出。

- readout 读多少？

  > 读 readout_times  之前到刺激开始的响应。

- readout_times 也不懂，什么时间间隔的 LSM 动态响应，LSM 网络动态响应又是什么？

  > `readout_times` 表示网络状态的读取时间点，分布在每次刺激结束后的 `stim_length + readout_delay = 60 ms`。
  >
  > `states` 中每个 `readout_times` 时刻的响应，实际是网络在 `readout_times` 前 **60ms 以内** 的神经活动的**加权平均结果。**
  >
  > 网络的状态响应，表示网络对该时间点之前的刺激的响应，是以 **readout_times 为基准的时间点上的加权输出**

- **这个衰减为什么是以 readout_times 进行衰减，而不是按照时间的系数从前向后衰减  ----------- 需要深入 LSM 才能理解**

  > 神经网络的动态响应包含快速和缓慢变化的成分，引入 `tau` **衰减系数**，可以对动态响应进行**平滑处理**，避免瞬时尖峰（spike）带来的噪声干扰。
  >
  > 刺激的响应虽然是**从刺激发生时开始衰减**，但 `tau` 的引入让我们对更靠近 `readout_times` 的活动赋予更高权重，**表示网络状态对最近活动更敏感**。

  ![image-20241229225800019](C:\Users\Yundid\AppData\Roaming\Typora\typora-user-images\image-20241229225800019.png)

- readout_times 的问题，和一开始生成的的spike train又有什么关系呢？

  > LSM 网络根据输入的尖峰序列进行计算，生成内部神经元的活动（动态响应）。这些响应受输入尖峰的影响，并通过网络的递归连接和抑制性神经元进行处理，最终以 `states` 形式输出。

- 提取网络响应的流程。

  > 1 每次刺激（尖峰序列）会在 `stim_times` 的时间点触发，并持续 `50 ms`。
  >
  > 2 刺激结束后，给网络 `10 ms` 的时间（`readout_delay`），让网络对刺激信号进行内部处理。
  >
  > 3 在 `stim_times + 60 ms`（即 `readout_times`）提取网络状态作为响应特征。
  >
  > 4 这些特征（`states`）用作分类器的输入，用于区分不同的输入模式。

- 刺激时刻 + spiketrain + LSM 网络响应之间的关系？刺激是施加在网络上的？那这个 spike 不是刺激后的响应？ 怎么又区别开网络响应的？ 

  > 网络接受的输入是 spiketrain 而不是刺激时刻。我总把 spike train 理解为 lsm 网络的响应，但实际是输入。
  >
  > `stim_time` 是用来生成输入的 spike train，并不直接参与 LSM 的计算过程。生成的两个神经元 spike train 是 LSM 的输入信号，LSM 根据这些输入信号进行动态处理，最终通过分类器完成对 XOR 逻辑关系的预测。

**Todo：**

- 需要把代码构建的 LSM 的全貌绘制出来。
- 注释都能补全？
- 一句话总结理论可以用于日常 gpt 的问答中
- 不看细节的话，可以想一想如何对当下的刺激模式进行 spike train 的编码。
- ~~mea 60通道的的spike train，这个好像只有一个维度？~~
- **下一步需要去看一下具体的从输入 到 网络处理 到 分类的全流程，目前并不清晰，尤其是 nest 的模拟过程，重复输入？**

- ~~依旧是不能直观理解这个 XOR 运算，因为输入不是两个维度不同的 spike train嘛，（如何做的异或运算）为什么最后预测标签的维度却是和刺激时刻的维度是一致的，意味着必须了解算法的执行流程~~

  

# 2024/12/30

- 在 ubuntu 系统上跑通了该 LSM 模型，作者提供了一个使用样例，基于 LSM 实现了对输入spike信号的异或逻辑分类任务。
  目前正基于该样例进行debug，想要先了解模型输入格式和可调的参数，然后考虑如何将我们实验的编码方案转换为模型可接受的输入进行孪生模拟。

  之后的话想要结合该模型源码，看一下他构建的 LSM 在结合nest下的一个运作模式，并结合文章进行复现，具备对模型的调整能力。

- 吸引子是什么？

- 模型自己写还是基于这种开源的网络去做？

- **模型输入要有生物学约束**

- **模型结构需要有生物学启发**

- **模型输出要有生物学验证**

- 模型上去尝试泛化性

- 图案进行反转

- 网络在不断变化，而不是简单的拟合

- 主动预防过拟合，欠拟合

- 生物临界稳态，有助于主动跳出过拟合，欠拟合状态，有助于泛化，学习的过程

**Done:**

- 那我还有一个问题，两个神经元的spiketrain是同时输入吗？

  > 同时输入，但 spike 的时间点是独立的，LSM 按照两个神经元中所有 spike 的时间先后顺序进行动态响应。

- 输入的时候带有时间信息吗？就是第一个spike和第二个spike的间隔，先输入一个spike响应后输入第二个？

  > spike 输入过程是并行的，但 LSM 会按 spike 时间点**逐步处理**这些输入，网络对 spike 的时间间隔具有敏感性。

- 网络何时具有的时间信息？因为输入的spike是离散的，网络如何明确这个readout_times，这个时间的基准点是哪里。

  > **readout_times 的基准点：** `readout_times` 是预先设定的，表示从网络中读取状态的时间点。**基准点是仿真时间的起点**。
  >
  > LSM 在 spike train 的时间点下进行响应即可，State 将提取基于基准点的某个跨度下的状态矩阵信息。

- 重现的想法？

  > 你重现的想法是认为这些spike已经输入了生物神经元产生了 spike 响应 然后输入 LSM 重现响应，但并不是。
  >
  > 因为 XOR 任务的特性，其实需要 LSM 进行 XOR 异或任务的背后，是要提取对应 spike train 下的响应，就是比如在 1s 附近，两个神经元都有响应，并也都按照时间先后顺序输入了 LSM 进行了动态响应，其实就是拿这个动态响应特征去做分类，看他能不能区分出都有响应的和不同响应情况的特征。
  >
  > 本质其实不包含重现的想法，其实就把 LSM 当成生物神经网络，输入包含我们想要处理的信息，基于时间去提取网络的动态特征，看该特征能不能表征出来我们输入的信息，能表征，则能分类。

  

**Todo：**

- 避免被重现干扰，需要考虑其他形式的输入的编码方式。
- 该去看 LSM 文章了，从文章了解 LSM 架构，进而拆解 LSM 部分实现代码，同时结合 Nest 架构，明确 Nest 架构下的 LSM 实现方式。
- 去看一下如何无缝将 ubuntu 系统进行迁移.
- B 站搜一下秋招以及读博申请的时间点。以及需要注意基本在什么时候准备。





我们通过多个感官同时感知世界，并在快速变化的环境中整合这些信息，实时做出决策。

可以把神经微回路想象成一个池塘，当不同的石子落入水中（输入扰动）时，水波的动态反映了当前石子的影响以及之前所有石子的累积效果。读取神经元就像一个“观察者”，能够从水波的动态中提取所需的信息，而不需要等水波完全平静（即稳定状态）。这使得整个系统能够更快、更高效地处理实时输入，并支持多个任务同时运行。

LSM 的创新之处就在于，它让网络“活”起来了，依赖的是动态波动，而不是明确的固定状态。这更接近于大脑的工作方式。

LSM 不需要像传统计算机那样，把内部状态严格分成一种一种的稳定状态（比如“存储0和1”），也不像吸引子网络需要收敛到某个稳定的吸引子。它完全依赖于输入引发的瞬态动态，并通过“读取器”神经元将这些动态转换成有用的输出结果。

- LSM 能处理哪些任务？
- 在快速变化的环境中，如何让递归神经电路实时处理多模态的连续输入？

LSM 利用高维动态系统的瞬态动态作为信息处理的核心，不依赖于任务特定的神经回路设计或稳定的内部状态。



**允许同一个神经网络的状态轨迹被不同读取模块并行用于不同任务。**



**液态状态机（LSM）的基础**：

- 本文的计算分析基于一种严谨的计算模型：液态状态机（Liquid State Machine, LSM）。

- 理论分析和计算机模拟中提炼了两大宏观属性，这两者是实现强大实时计算的必要和充分条件：

  1. 分离属性 (Separation Property, SP)

     ：

     - 反映不同输入流导致的系统内部状态轨迹之间的差异。
     - 例如，对于物理液体，SP可以表示不同扰动序列导致的波浪模式之间的差异。

  2. 近似属性 (Approximation Property, AP)

     ：

     - 表示读取器的分辨率和重新编码能力，即将不同内部状态区分并转换为目标输出的能力。
     - SP 主要取决于液体本身的复杂性，而 AP 则更多取决于读取机制对特定任务的适应能力。



CNN 等传统网络通过**层层卷积和非线性变换**提取输入数据的特征，这种过程是静态的：给定固定输入，会始终生成固定的特征输出。

CNN 的输出由最后几层的神经元权重直接决定，这些权重在训练中被优化到任务所需的固定值。换句话说，CNN 的“读取器”（全连接层）是高度依赖于任务的，且必须通过反向传播优化。CNN 的输出依赖于训练过程中优化的全连接层权重，这些权重只针对当前任务有效。若任务变化，则需要重新训练整个网络。



**LSM 的特点**：LSM 不需要反向传播训练整个网络，仅需对读取器（readout）进行**简单线性映射即可完成任务（比如分类或回归）**。

可以通过简单的线性回归实现新的任务学习，而无需重新训练整个 LSM 网络。



但 CNN 本身并不具备天然的高维动态响应。它只是在每次**前向传播中对静态输入提取固定特征**。

因此，CNN 很难通过动态的高维状态区分极其相似的输入时间序列。

LSM 的内部状态由时间序列输入驱动，每个时刻的状态都与之前的输入序列相关。这种高维状态变化天然满足分离属性，可以区分极其细微的输入差异。





**3 Liquid State Machines**

LSM就像一片高维的动态湖面，利用它的分离能力（不同输入序列产生不同波纹）和读出能力（从波纹中提取信息），实现了实时的复杂计算，而不需要固定的存储状态。

然而，图灵机在处理静态离散输入的离线计算方面具有通用计算能力，而LSM则在处理连续时间中具有逐渐消失记忆的模拟函数的实时计算方面具有非常特殊的通用计算能力。

LSM的实时计算依赖于液态状态的分离能力和读出映射的近似能力，而不是传统模型中依赖的稳定状态存储。

与液态过滤器的通用性不同，读出映射是任务特定的。

**4 Universal Computational Power of LSMs for Time-Varying Inputs**

> 本节的核心是解释为什么 LSM 能在数学上实现“普遍计算能力”。这一理论基础保证了 LSM 可以被用于广泛的实时计算任务，无论输入是连续的时间信号，还是离散的尖峰序列。

**一项数学定理（见附录 A）证明了**，在满足以下两个抽象性质的条件下，无论具体结构或实现方式如何，液态状态机（LSM）都具备这种普遍计算能力：

1. **点分离特性（pointwise separation property）**：液体滤波器 LML_MLM 的基础滤波器类别必须满足此特性。
2. **逼近特性（approximation property）**：读取映射 fMf_MfM 的函数类别必须满足此特性。

![image-20250106121152182](C:\Users\Yundid\AppData\Roaming\Typora\typora-user-images\image-20250106121152182.png)



**图灵机 有限状态机 吸引子网络 LSM 对比**



此外，这一理论还可以扩展到处理尖峰序列（spike train，离散事件的连续时间表示）作为输入的情况。在这种情况下，输入函数 u(⋅)u(·)u(⋅) 的第 iii 维分量 ui(⋅)u_i(·)ui(⋅) 是一个只取值为 0 和 1 的函数，其中 ui(t)=1u_i(t) = 1ui(t)=1 表示第 iii 个前馈神经元在时间 ttt 发生了尖峰。尽管 ui(⋅)u_i(·)ui(⋅) 不是连续函数，而是一个点事件的序列，**附录 A 的定理 2 提供了使用 LSM 来逼近任何生物学上相关尖峰序列计算的理论基础。**

**淡化记忆**：LSM 不需要记住所有历史信息，它只对最近一段时间的输入敏感（就像一杯水的波纹，虽然最终会平静，但短时间内可以记住石子造成的变化）。

**时间不变性**：LSM 的输出随输入的时间偏移同步变化，就像你丢入水中的石子改变了波纹，但这些变化始终和丢入的时间点对应。



读取映射的输出仅仅依赖于当前时刻的液体状态，而不需要直接考虑系统过去的状态。

系统的记忆功能主要体现在液体的动态演化中。液体的状态 xM(t)x_M(t)xM(t) 是系统对过去输入的响应的体现，即系统的“记忆”以动态形式存储在液体状态中。

读取映射从当前液体状态中提取信息，而不必存储历史状态。

在实际生物系统中，读取映射可能会因为神经可塑性（如突触权重的变化）而具有某种记忆功能。

因此，读取映射在真实生物系统中可能不仅仅是“无记忆”的工具，它可能对系统的整体记忆能力有所贡献。

- 可能创新的点

将读取映射视为“无记忆”设备，液体作为“记忆设备”，这种划分仅仅是为了分析和概念上的清晰性，并不是模型本质的限定条件。



**5 部分以及之后是相关使用样例以及分离性和近似性的探究，以及多模态任务的探究**







# 2025/1/6

``` PYTHON
self._rec_detector = nest.Create('spike_detector', 1)
nest.Connect(self.rec_nodes, self._rec_detector)
nodes = nest.Create('iaf_psc_exp', n_E + n_I,
                    {'C_m': 30.0,  # 1.0,
                     'tau_m': 30.0,  # Membrane time constant in ms
                     'E_L': 0.0,
                     'V_th': 15.0,  # Spike threshold in mV
                     'tau_syn_ex': 3.0,
                     'tau_syn_in': 2.0,
                     'V_reset': 13.8})
nest.SetStatus(nodes, [{'I_e': 14.5} for _ in nodes])
```

- 创建LIF神经元的各个参数的作用是什么？

- nest.SetStatus(nodes, [{'I_e': 14.5} for _ in nodes])：

  为所有神经元设置外部电流 I_e，模拟持续的外部输入。

  注释掉的部分展示了如何为神经元设置随机化的外部电流输入。

  

- 这个电流的作用是什么？







# 资源

- https://developer.aliyun.com/article/1579867

  > 储层计算相关的文章 2020 - 2024

- https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/137446002

  > 临界性清华综述

